{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fdd43bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017a7780",
   "metadata": {},
   "source": [
    "# Project objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260a0893",
   "metadata": {},
   "outputs": [],
   "source": [
    "Main Goal of this project is to predict the risk of a Heart Attack a person have, By using various\n",
    "Algorithms to predict the result and see which one suits best."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b273dff2",
   "metadata": {},
   "source": [
    "# Understanding of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4623ba2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.Age : \n",
    "    1.Age of the patient-(25-80)\n",
    "    2.Age above 50 there have frequency of having Heart disease\n",
    "    \n",
    "2.exercise induced angina/Physical health (exang): \n",
    "    1.exercise induced angina (1 = yes; 0 = no)\n",
    "    2.chest pain that comes on when you are walking uphill or in the cold weather may be angina.\n",
    "    \n",
    "3.number of major vessels(ca): \n",
    "    1.number of major vessels (0-4)\n",
    "    2.The RCA supplies blood to your right atrium and right ventricle (where deoxygenated blood\n",
    "    goes before heading to the lungs).\n",
    "\n",
    "4.Chest Pain type /physical health & Mental health(cp) : \n",
    "    Chest Pain type \n",
    "    Value 0: typical angina\n",
    "        \n",
    "chest pain by physical exertion or emotional stress, Women and elderly patients are usually\n",
    "have a typical symptoms both at rest and during stress.\n",
    "\n",
    "    Value 1: atypical angina\n",
    "It is a chest pain of heart muscle doesn't get an adequate supply of oxygenated blood.\n",
    "\n",
    "    Value 2: non-anginal pain\n",
    "recurring pain in your chest — typically, behind your breast bone and near your heart — that is\n",
    "not related to your heart.\n",
    "\n",
    "    Value 3: asymptomatic\n",
    "red spots are symptomatic of measles and chest pain is symptomatic of a heart attack \n",
    "    \n",
    "5.blood pressure(trtbps) : \n",
    "    resting blood pressure (in mm Hg) range in 80 to 120\n",
    "    resting blood pressure anything above 130-140 is generally of concern(Hypertension (High Blood Pressure) case)\n",
    "    trestbps(BP)-200 max condition for outliers\n",
    "    Max BP patient in the range of 370/360 found\n",
    "\n",
    "6.cholestoral(chol) :\n",
    "    \n",
    "    cholestoral in mg/dl \n",
    "    \n",
    "    chol: greater than 200 is of concern depend on age\n",
    "        \n",
    "    max chol is about 500\n",
    "    \n",
    "    outlier upto=400 chol\n",
    "    \n",
    "    Two Types of cholesterol in the blood\n",
    "\n",
    "    1.LDL (low-density lipoprotein)\n",
    "\n",
    "    Having high levels of LDL cholesterol in the blood can lead to the build-up of cholesterol in the arteries, which can \n",
    "    narrow the blood vessels and increase the risk of heart disease and stroke.\n",
    "\n",
    "    Desirable Range: Less than 100 mg/dL is typically considered optimal for individuals without underlying risk factors.\n",
    "\n",
    "    Borderline High Range: 130-159 mg/dL suggests an intermediate risk level.\n",
    "\n",
    "    High Range: 160 mg/dL and above indicates an increased risk of cardiovascular diseases.\n",
    "\n",
    "    Lower levels of LDL cholesterol are generally associated with a lower risk of heart disease.\n",
    "\n",
    "    2.HDL Cholesterol (Good Cholesterol)\n",
    "\n",
    "    higher levels of HDL cholesterol are generally considered beneficial as it helps remove excess cholesterol from the bloodstream.\n",
    "\n",
    "    Desirable Range: 40 mg/dL or higher is considered desirable for men and women.\n",
    "\n",
    "    Higher levels of HDL cholesterol are generally associated with a lower risk of heart disease.\n",
    "\n",
    "    Test \n",
    "    A lipid profile blood test can measure the levels of LDL cholesterol, HDL cholesterol.\n",
    "    \n",
    "7.tryglyceride_level:fat in blood\n",
    "    Normal-Less than 150 milligrams per deciliter (mg/dL)_ \n",
    "    high- 200-499 \n",
    "    very high- 500 \n",
    "    pancreas- helps to digest food \n",
    "    pancreatitis problem occur it damage pancreas organs so appetite problem may occur\n",
    "\n",
    "7.diabetis/sugar(fbs):\n",
    "    (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\n",
    "    A fasting blood sugar level of 99 mg/dL or lower is normal, 100 to 125 mg/dL indicates you\n",
    "    have prediabetes, and 126 mg/dL or higher indicates you have diabetes.\n",
    "    BP- 1000 highest dangerous when it is greater than 300\n",
    "\n",
    "8.Heart rate(thalach) :\n",
    "    Normal Heart rate between 60 to 100 beats per minute.\n",
    "    vary upto 200, chance of heart dieses increases max heart rate after 100\n",
    "    outlires upto=200\n",
    "    \n",
    "9.BMI:\n",
    "    BMI weight and height ratio w /h^2 kg/m ^2, \n",
    "    Normal range is 18.5-24.9  <18.5 underweight, 24.9 > overweight -30\n",
    "    after 30-35 obese means very fat 44% higher risk\n",
    "    35> 88% of higher risk\n",
    "    40> 250% of higher risk\n",
    "    200 kg-63 bmi\n",
    "    150 kg-48 bmi\n",
    "    outliers range for BMI is 45\n",
    "    \n",
    "10.Heridty:\n",
    "    is there any one who have heart diesese in thier family.\n",
    "    \n",
    "12.Stroke :\n",
    "    People with a thal value of 2 (defect corrected: once was a defect but ok now) are more \n",
    "    likely to have heart disease. \n",
    "\n",
    "15.Gender:\n",
    "    M|F|T\n",
    "    \n",
    "16.slip time:\n",
    "    8 hrs sleep is best slip time\n",
    "    \n",
    "17.Ashtma:\n",
    "    yes or no \n",
    "\n",
    "18.target : 0= less chance of heart attack 1= more chance of heart attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f852cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Imp features\n",
    "BMI->BP->choelstrol->tryglyceride_level->Dibetis->Heart Rate->chest pain type->stroke->Age->hereidity\n",
    "Left shoulder pain->Rapid or irregular heartbeat->stomach pain->Swelling in the legs,ankles,feet\n",
    "Reduced ability to exercise->Sexual health problems->Swelling of the belly area (abdomen)->back \n",
    "pain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5e972f",
   "metadata": {},
   "source": [
    "# Total fetures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88510c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.BMI_\n",
    "2.BP_\n",
    "3.Cholestrol level_\n",
    "4.tryglyceride_level-Normal-Less than 150 milligrams per deciliter (mg/dL)_ fat in blood\n",
    "4.Heart rate_\n",
    "5.dibetis_\n",
    "6.Age_**\n",
    "7.Physical health /exercise induced angina(exang)_*\n",
    "8.Stroke/thal_**\n",
    "9.mental health_*\n",
    "10.Chest Pain type chest pain type_**\n",
    "11.Heridity_*\n",
    "12.sleep time_\n",
    "13.smoking_*\n",
    "14.number of major vessels_*\n",
    "15.resting electrocardiographic results(rest_ecg)_**\n",
    "16.Old peak\n",
    "17.sex_*\n",
    "18.Race_**\n",
    "19.GenHealth_**\n",
    "20.Target_*\n",
    "21.Shortness of breath_*\n",
    "22.Left shoulder pain_*\n",
    "23.Rapid or irregular heartbeat_*\n",
    "24.stomach pain_*\n",
    "25.Swelling in the legs, ankles and feet_**\n",
    "26.Reduced ability to exercise_*\n",
    "27.Sexual health problems_*\n",
    "28.Swelling of the belly area (abdomen)_*\n",
    "29.ashthma_*\n",
    "30.back pain_*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a34a58",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6611a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.Import libraray\n",
    "\n",
    "2.Data gather:\n",
    "    df=pd.read_csv('heart (2).csv')\n",
    "    \n",
    "3.1.Data analyse numrically(EDA):\n",
    "    1.df.head() &df.tail()\n",
    "    2.df.shape\n",
    "    3.df.axes\n",
    "    4.df.column()\n",
    "    5.df.info()\n",
    "    6.df.describe\n",
    "    7.df.isnull.sum()\n",
    "    8.df[df.duplicated()]\n",
    "    9.check hypothesis\n",
    "    10.df.corr()\n",
    "    \n",
    "3.2.Data analyse by garphs(EDA):\n",
    "    1.check correlation:\n",
    "        sns.heatmap(df.corr(),annot = True)\n",
    "\n",
    "    2.check corelation of all independent variable with each other:\n",
    "        sns.pairplot(df,hue='output',data=df)\n",
    "        \n",
    "    3.scatter plot of all independent variable:\n",
    "        plt.scatter(df['chol'],df['trestbps'], c = df['age'],cmap = 'rainbow')\n",
    "        \n",
    "    4.check the probability of having heart diesease:\n",
    "        sns.countplot(x='target',data=df)\n",
    "        \n",
    "    5.Plot the countplot on the basis of all parameter like target vs age,BMI,Dibties etc too see\n",
    "    is there any chance of heart dieases:\n",
    "        display(sns.countplot(x = 'target', hue='age',data=df,color='Green'))\n",
    "        \n",
    "    6.seaprately plot all data point of age,sex,BMI,Dibties,vs count coloumn to see on which age \n",
    "    range having more chance of getting heart disease:\n",
    "        sns.countplot(x='age',data=df)\n",
    "        \n",
    "    7.get and store all values in categorial and continuous variables by using for loop,unqiue \n",
    "    value function and append function.\n",
    "    \n",
    "    8.Plot histogram of all the target varibale vs rest features of continous and cateogrial in a\n",
    "    dataset to see is there any possibility of having heart dieases using for loop and enumerate\n",
    "    function\n",
    "    \n",
    "    9.Get value_counts and assign chest pain name to every index number in this features :\n",
    "        cp_data= df['cp'].value_counts().reset_index()\n",
    "        cp_data['index'][3]= 'asymptomatic'\n",
    "        cp_data['index'][2]= 'non-anginal'\n",
    "        cp_data['index'][1]= 'Atyppical Anigma'\n",
    "        cp_data['index'][0]= 'Typical Anigma'\n",
    "        cp_data\n",
    "    10.Now plot which pain having more chance of  heart diesease:\n",
    "        sns.barplot(x=cp_data['index'],y= cp_data['cp'])\n",
    "    \n",
    "    13.By using kde plot see in which range or on which value having more chance of heart disease\n",
    "    on the basis of BP,BMI,heart rate etc plot seprate kde graphs for all check :\n",
    "        sns.distplot(df['trtbps'], kde=True, color = 'magenta')\n",
    "        plt.xlabel(\"Resting Blood Pressure (mmHg)\")\n",
    "        \n",
    "    check the data is normally distrubuted around the best fit line or not\n",
    "    \n",
    "        sns.distplot(df['thalachh'], kde=True, color = 'teal')\n",
    "        plt.xlabel(\"Maximum Heart Rate Achieved (bpm)\")  \n",
    "        etc..\n",
    "        \n",
    "    14.Plot Boxplot to see the outliers in the data set:\n",
    "        df.boxplot()\n",
    "        \n",
    "    15.also see outliers of the all individual conctinous variable:\n",
    "        sns.boxplot(x='thalach',data=df)\n",
    "        sns.boxplot(x='age',data=df)\n",
    "        sns.boxplot(x='trestbps',data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459892b7",
   "metadata": {},
   "source": [
    "# Feature engineering (Data preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb024f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.Encoding:\n",
    "    \n",
    "    1.check how many objective and unique value feature which is categorial in nature:\n",
    "        df.info()\n",
    "    \n",
    "    2.check value_counts:\n",
    "        df['AgeCategory'].value_counts()\n",
    "    \n",
    "    3.There is 80 or older unique value which categorial so replace that 80 0r older with 80:\n",
    "        df['AgeCategory'].replace({'80 or older':'80'},inplace=True)\n",
    "        \n",
    "    4.There are many category  in a age coloumn so apply one hot encoder or get dummies over age \n",
    "    feature:\n",
    "        one_hot_enco = OneHotEncoder()\n",
    "        array = one_hot_enco.fit_transform(df[['AgeCategory']]).toarray()\n",
    "        df= pd.DataFrame(array,columns=sorted(df['AgeCategory'].unique()))\n",
    "        df\n",
    "        \n",
    "    5.target heart disease coloumn having categorial values convert it into :\n",
    "        label_encoder = LabelEncoder()\n",
    "        df1= label_encoder.fit_transform(df['target'])\n",
    "        df1\n",
    "        \n",
    "    6.value_countson target feature:\n",
    "        df['HeartDisease'].value_counts()\n",
    "        \n",
    "    7.df['GenHealth'].value_counts():\n",
    "        Very good 113858\n",
    "        Good 93129\n",
    "        Excellent 66842\n",
    "        Fair 34677\n",
    "        Poor 11289\n",
    "        Name: GenHealth\n",
    "            \n",
    "    8.Do label encoding here:\n",
    "        label_encoder = LabelEncoder()\n",
    "        df3= label_encoder.fit_transform(df['GenHealth'])\n",
    "        df['GenHealth']=df3\n",
    "        \n",
    "    9. value_counts on 'Race':\n",
    "        df['Race'].value_counts()\n",
    "        \n",
    "        White 245212\n",
    "        Hispanic 27446\n",
    "        Black 22939\n",
    "        Other 10928\n",
    "        Asian 8068\n",
    "        American Indian/Alaskan Native 5202\n",
    "        Name: Race\n",
    "        \n",
    "    10.do one hot encoding here on 'Race':\n",
    "        one_hot_enco = OneHotEncoder()\n",
    "        df3=  one_hot_enco.fit_transform(df['Race'])\n",
    "        df['Race']=df3\n",
    "    \n",
    "    11.df['Stroke'].value_counts()\n",
    "    \n",
    "    12.apply label encoding on 'Stroke':\n",
    "        label_encoder = LabelEncoder()\n",
    "        df1= label_encoder.fit_transform(df['Stroke'])\n",
    "        df1\n",
    "    13.Physical health /exercise induced angina(exang) on this do label encoding here:\n",
    "        only two category: yes | No\n",
    "            \n",
    "    14.Stroke/thal means how many heart attack happened previously do one hot encoding here:\n",
    "        four category-A,B,C,D\n",
    "        \n",
    "    15.Mental health apply label encoding\n",
    "    \n",
    "    16.Chest Pain type chest pain type apply one hot encoding here:\n",
    "        four category:1.typical angina 2.atypical angina 3.non-anginal pain 4.asymptomatic\n",
    "            \n",
    "    17.apply label encoding on,heridity,smoking,sex,target: \n",
    "        only two categories: yes or no\n",
    "            \n",
    "    18.resting electrocardiographic results(rest_ecg) apply one hot encoding:\n",
    "        Three categories:\n",
    "            1.'normal'\n",
    "            2.'having ST-T wave abnormality'\n",
    "            3.'showing probable or definite left ventricular hypertrophy by Estes'\n",
    "    19.Apply label encoding on fetures of Shortness of breath,Left shoulder pain, Rapid heartbeat\n",
    "    stomach pain ,Reduced ability to exercise,Sexual health problems,Swelling of the belly area\n",
    "    astma,back pain:\n",
    "        categories for all only:yes or no\n",
    "      \n",
    "    20.Swelling apply one hot encoding here:\n",
    "        categories:1.legs 2.ankles 3.feet     \n",
    "            \n",
    "Apply Label encoding here:\n",
    "    1.Heridity\n",
    "    2.smoking\n",
    "    3.sex\n",
    "    4.target\n",
    "    5.Shortness of breath\n",
    "    6.Left shoulder pain\n",
    "    7.Rapid or irregular heartbeat\n",
    "    8.stomach pain\n",
    "    9.Reduced ability to exercise\n",
    "    10.Sexual health problems\n",
    "    11.Swelling of the belly area (abdomen)\n",
    "    12.ashtma\n",
    "    13.back pain\n",
    "    \n",
    "Apply one hot encoding here:\n",
    "    1.Age\n",
    "    2.Stroke/thal\n",
    "    3.Chest Pain type chest pain type\n",
    "    4.resting electrocardiographic results(rest_ecg)\n",
    "    5.race\n",
    "    6.GenHealth\n",
    "    7.Swelling in the legs, ankles and feet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef777dec",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a6d94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.check null values:\n",
    "    df.isnull.sum()\n",
    "    \n",
    "2.drop null values:\n",
    "    df.dropna()\n",
    "    \n",
    "3.find duplicate rows:\n",
    "    df[df.duplicated()]\n",
    "    \n",
    "4.drop or get only unique rows:\n",
    "    df=df[~df.duplicated()]\n",
    "    \n",
    "5.cheack outliers of every features and drop that outliers:\n",
    "    sns.boxplot(x='chol',data=df)\n",
    "    df.drop(df.loc[df['chol']>500].index, axis = 0,inplace=True)\n",
    "    \n",
    "6.Tackle with multicolinearity:\n",
    "    1.In linear and logistic regression\n",
    "    2.if 2 feature are highly corelated with each other now how handle this i use corelation\n",
    "    concept if two features are 90% corelated then i remove that feature\n",
    "    3.combine corelated fetures\n",
    "    4.PCA\n",
    "    5.Also penalise the variable by using ridge and lasso regression\n",
    "    6.drop the highly corelated features\n",
    "    7.we also check p-value and if p-value is higher then drop that feature\n",
    "    8.we can merge both two features\n",
    "    9.use component having eigen values is higher than 1\n",
    "    10.use VIF technique where vIF>5drop that feature or combine two corelated varibles into one\n",
    "    and remove the highly corelated varible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1836a7e3",
   "metadata": {},
   "source": [
    "# Minmax scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8246999b",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.import Libraries\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "2.Minmax scaler:\n",
    "    normal_scalar= MinMaxScaler()\n",
    "    x_scaled=normal_scalar.fit_transform(df)\n",
    "    df=pd.DataFrame(x_scaled,columns=df.columns)\n",
    "    df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73b1f63",
   "metadata": {},
   "source": [
    "# split dependent and independent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b2655c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('target',axis=1)\n",
    "y= df.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431d2945",
   "metadata": {},
   "source": [
    "# Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f074424",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.check value count of target features:\n",
    "    df['target'].value_counts()\n",
    "    \n",
    "2.pip install imbalanced-learn\n",
    "\n",
    "3.!pip install scikit-learn==0.18.2\n",
    "\n",
    "4.from imblearn.over_sampling import SMOTE\n",
    "\n",
    "5.import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# over = SMOTE(sampling_strategy=0.1)\n",
    "oversample = SMOTE()\n",
    "x, y = oversample.fit_resample(x, y)\n",
    "\n",
    "6.x.shape & y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04af95c7",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3707c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.Logistic regression\n",
    "2.KNN classifier\n",
    "3.Decision Tree classifier\n",
    "4.Adaboost\n",
    "5.XgBoost\n",
    "6.Random Forest\n",
    "7.Naive bayes\n",
    "8.SVM classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348216b4",
   "metadata": {},
   "source": [
    "# 1.Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3333c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.Train test split:\n",
    "    x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=1)\n",
    "    \n",
    "2.call logistics regression model from sklearn :\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    \n",
    "3.create logistic regression model:\n",
    "    logreg= LogisticRegression()\n",
    "    \n",
    "4.Training:\n",
    "    logreg.fit(x_train,y_train)\n",
    "    \n",
    "5.Predict on test data:\n",
    "    y_pred = logreg.predict(x_test)\n",
    "    y_pred\n",
    "    \n",
    "6.Get | tp fp tn fn |:\n",
    "    cnf_matrix = confusion_matrix(y_test,y_pred)\n",
    "    cnf_matrix\n",
    "    \n",
    "7.check test accuracy,precision, recall:\n",
    "    accuracy_score(y_test,y_pred)\n",
    "    precision_score(y_test,y_pred)\n",
    "    recall_score(y_test,y_pred)\n",
    "    \n",
    "8.Do training on training data and get Training accuracy:\n",
    "    y_pred_train=logreg.predict(x_train)\n",
    "    accuracy_score(y_train,y_pred_train)\n",
    "    \n",
    "9.confusion matrix to get accuracy,precision, recall:\n",
    "    print(classification_report(y_test,y_pred))\n",
    "\n",
    "10.apply lasso and ridge regression and again repeat all this procedure and check accuracys\n",
    "\n",
    "11.all models built in same way just do pruning before DT tree and do hyperparamter for all\n",
    "other models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10405194",
   "metadata": {},
   "source": [
    "# Pruning for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd39bc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "1st:---->\n",
    "    values = DT_model.cost_complexity_pruning_path(x_train,y_train)\n",
    "    print(values)\n",
    "    \n",
    "2nd:---->\n",
    "    ccp_alpha_list = values['ccp_alphas']\n",
    "    ccp_alpha_list\n",
    "\n",
    "3rd:---->\n",
    "train_acc=[]\n",
    "test_acc = []\n",
    "for ccp_alpha in ccp_alpha_list:\n",
    "    dt_model=DecisionTreeClassifier(random_state=1,ccp_alpha=ccp_alpha)\n",
    "    dt_model.fit(x_train,y_train)\n",
    "    \n",
    "    train_acc.append(dt_model.score(x_train,y_train))\n",
    "    test_acc.append(dt_model.score(x_test,y_test))\n",
    "\n",
    "4th:--->\n",
    "    max(test_acc)\n",
    "    max(train_acc)\n",
    "    len(test_acc)\n",
    "    test_acc.index(max(test_acc))\n",
    "    ccp_alpha_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a963d47",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e299d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.Do tuning:\n",
    "    dt_clf=DecisionTreeClassifier()\n",
    "    hyperparameters = {'criterion':[\"entropy\",'Gini'],\n",
    "                        'max_depth':np.arange(4,25),\n",
    "                      'min_samples_leaf':np.arange(2,4),\n",
    "                      'min_samples_split':np.arange(2,4)}\n",
    "    gscv_dt_model=GridSearchCV(dt_clf,hyperparameters,cv=3)\n",
    "    gscv_dt_model\n",
    "\n",
    "2.Give training as well find best parameter who give best accuracy:\n",
    "    gscv_dt_model.fit(x_train,y_train)\n",
    "    gscv_dt_model.best_params_\n",
    "\n",
    "3.testing Accuracy after tunning:\n",
    "    y_pred_gscv = gscv_dt_model.predict(x_test)\n",
    "    accuracy_score(y_test,y_pred_gscv)\n",
    "\n",
    "4.training Accuracy after Tunning:\n",
    "    y_train_gscv = gscv_dt_model.predict(x_train)\n",
    "    accuracy_score(y_train,y_train_gscv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29d451b",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators':np.arange(10,20),\n",
    "         'criterion': ['gini','entropy'],\n",
    "         'max_depth':np.arange(2,20),\n",
    "         'min_samples_leaf':np.arange(1,10),\n",
    "         'min_samples_split':np.arange(2,10),\n",
    "         'max_features':['auto'],\n",
    "         'random_state':[10],\n",
    "         'ccp_alpha':np.arange(0.01,1,0.1)}\n",
    "\n",
    "rf_model=RandomForestClassifier()\n",
    "rf_gscv=GridSearchCV(rf_model,param_grid=params)\n",
    "rf_gscv.fit(x_train,y_train)\n",
    "rf_gscv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f68434",
   "metadata": {},
   "source": [
    "# 1.what are the pblms faced in ML project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361bfe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.very first problem i faced to understanding of there have different parameter need to understand \n",
    "this so i able to to work on that very well.\n",
    "2.multicolinirty\n",
    "3.outliers\n",
    "4.imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9464e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data preparation is the process of gathering, combining, structuring and organizing data so it\n",
    "can be used in business intelligence (BI), analytics and data visualization applications.\n",
    "\n",
    "Data preparation tools will clean up your data for you, improving the quality so you can start \n",
    "working with it faster. That includes:\n",
    "\n",
    "Standardizing formats\n",
    "\n",
    "Removing inaccurate data\n",
    "\n",
    "Removing duplicates\n",
    "\n",
    "Flagging incomplete data\n",
    "\n",
    "explain whole prcoess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf679eae",
   "metadata": {},
   "source": [
    "### 2.Roles and Responsibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce0e518",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
